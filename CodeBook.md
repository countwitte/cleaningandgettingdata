# Codebook for the Getting and Cleaning Data Course Project from Coursera & Johns Hopkins

This code book provides a high level overview of the workflow applied to the data in run_analysis.r which supplements the comments in the script file. In addition a description of output dataset and the variable is provided. 

## Data Transformation Workflow

* The data from Smartlab represents 30 participants wearing smart phones while carrying out 6 activities, and is split into test and training datasets.
* The data are held in seperate files for each dataset and these files represent: the measurement data (dervied from device's sensors and referred to as features in the data documentation), the activity code and label, and the numeric subject identifier.
* The script reads in the seperate files and creates a complete dataset for both test and training that includes the measurement data, the actvity, the subject identifier and the measurement (feature) variable labels.
* These to datasets are then merged so that all data for all subjects is contained in a single dataframe.
* The script then subsets the data, removing columns that do not provide values on the mean or standard deviation of a given measurement. This was done with reference to the data documentation that states that feature labels ending in mean() correspond to the Mean value and std() corresponds to Standard deviation.
* Descriptive value labels were added to the activity variable.  
* Finally the output dataset tidydata.txt was generated by summarising the data: the average value of each measurement is given by activity for each subject in the dataset.

## Variables & Values

The dataset contains 180 observations (30 participants x 6 activities) of 68 variables. Each variable value is an average of recorded measurements for that participant, for that activity.

### Subject

Subject Identifier type:Numeric with values in the range 1:30  

### Activity

Activity being measured type:String with the values WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING 

### The remaining variables:

The remaining variables in the dataset are derived measurements from the device, in each case the variable name is constructed as follows:

[the derived measurement e.g. tBodyAcc]-[the average estimated value e.g. mean()]-[the axis e.g. X]

The documentation provided by Smartlab states the following to better describe the feature labels:

> The features selected for this database come from the accelerometer and gyroscope 3-axial raw signals tAcc-XYZ and tGyro-XYZ. These time domain signals (prefix 't' to denote time) were captured at a constant rate of 50 Hz. Then they were filtered using a median filter and a 3rd order low pass Butterworth filter with a corner frequency of 20 Hz to remove noise. Similarly, the acceleration signal was then separated into body and gravity acceleration signals (tBodyAcc-XYZ and tGravityAcc-XYZ) using another low pass Butterworth filter with a corner frequency of 0.3 Hz. 

Subsequently, the body linear acceleration and angular velocity were derived in time to obtain Jerk signals (tBodyAccJerk-XYZ and tBodyGyroJerk-XYZ). Also the magnitude of these three-dimensional signals were calculated using the Euclidean norm (tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag, tBodyGyroJerkMag). 

Finally a Fast Fourier Transform (FFT) was applied to some of these signals producing fBodyAcc-XYZ, fBodyAccJerk-XYZ, fBodyGyro-XYZ, fBodyAccJerkMag, fBodyGyroMag, fBodyGyroJerkMag. (Note the 'f' to indicate frequency domain signals). 

These signals were used to estimate variables of the feature vector for each pattern:  
'-XYZ' is used to denote 3-axial signals in the X, Y and Z directions. 